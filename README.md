# AI Blog Engine
[![Ask DeepWiki](https://devin.ai/assets/askdeepwiki.png)](https://deepwiki.com/Vishwajeet3007/ai_blog_engine)

An autonomous blog writing system powered by a LangGraph multi-agent pipeline. The application plans, researches, writes, and packages technical blog posts, complete with AI-generated images.

## Architecture

The system is split into a backend graph-based pipeline and a frontend user interface.

### Backend (`bwa_backend.py`)
The core logic is a LangGraph state machine that orchestrates multiple agents to generate a complete blog post.
- **State Management**: Uses a typed dictionary (`State`) to pass information between nodes, ensuring data consistency.
- **Router**: An initial node inspects the topic and determines the best execution mode: `closed_book` (for evergreen topics), `hybrid` (for topics needing fresh examples), or `open_book` (for time-sensitive news).
- **Research**: When required, this node uses the Tavily API to perform web searches based on queries generated by the router, gathering evidence to ground the blog post.
- **Orchestration & Planning**: A planning agent creates a structured outline for the blog, defining the title, audience, tone, and a list of specific sections (tasks).
- **Parallel Execution**: The graph fans out to multiple worker agents, each responsible for writing a single section of the blog post in parallel.
- **Content Reduction & Finalization**: A reducer node merges the written sections in order. It then initiates an image generation pass, where it decides on necessary visuals, generates them using Google's Gemini API, and inserts them into the final markdown file.

### Frontend (`bwa_frontend.py`)
A user-friendly web interface built with Streamlit.
- **Input**: Allows users to submit a blog topic and an "as-of" date.
- **Live Monitoring**: Streams real-time progress logs from the LangGraph execution, providing visibility into the agent's process.
- **Tabbed Output**: Organizes the final output into clear tabs for the writing plan, research evidence, a live preview of the blog, generated images, and detailed logs.
- **History**: Loads and displays previously generated blog artifacts from the local `blogs/` directory.
- **Export**: Packages the final blog (markdown file and images) into a single ZIP file for easy download and publishing.

## Quickstart

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Configure Environment
Create a `.env` file in the root directory and add the necessary API keys. The Tavily API key is recommended for research-intensive topics, and the Google API key is required for image generation.
```env
OPENAI_API_KEY="sk-..."
TAVILY_API_KEY="tvly-..."
GOOGLE_API_KEY="AIza..."
```

### 3. Run the App
Launch the Streamlit frontend.
```bash
streamlit run bwa_frontend.py
```
Navigate to the local URL provided by Streamlit to use the application.

## Repository Files
- `bwa_backend.py`: Contains the LangGraph definition, agent logic, and state management for the blog generation pipeline.
- `bwa_frontend.py`: The Streamlit application that provides the user interface.
- `requirements.txt`: A list of all Python dependencies required to run the project.
- `blogs/`: The default output directory where generated blog posts and associated images are saved.
- `VERSION_REVIEW.md`: A comparative analysis of two development versions of the application.

